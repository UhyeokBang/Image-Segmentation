{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model.UNet import UNet\n",
        "from model.DeepLab import DeepLabV3Plus\n",
        "from model.HRNet import HRNetV2\n",
        "\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, data_type, mode):    \n",
        "    self.mode = mode\n",
        "    self.input, self.label = [], []\n",
        "\n",
        "    # 작업할 폴더의 경로\n",
        "    path = './dataset/{0}s'.format(data_type) \n",
        "\n",
        "    self.input_path = '{0}/{1}/{2}'.format(path, self.mode, \"data\")\n",
        "    self.label_path = '{0}/{1}/{2}'.format(path, self.mode, \"label\")\n",
        "\n",
        "    # 폴더 안에 있는 데이터 파일들의 이름을 추출\n",
        "    data_names = [name.split('.')[0] for name in os.listdir(self.input_path)]\n",
        "\n",
        "    # 데이터 전처리\n",
        "    for data_name in data_names:\n",
        "        self.input.append('{0}/{1}.png'.format(self.input_path, data_name))\n",
        "        self.label.append('{0}/{1}.png'.format(self.label_path, data_name))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input = cv2.cvtColor(cv2.imread(self.input[index]), cv2.COLOR_BGR2RGB)\n",
        "    label = cv2.imread(self.label[index], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    input = torch.FloatTensor(input).permute(2, 0, 1)\n",
        "    label = torch.LongTensor(label)\n",
        "\n",
        "    i, j, h, w = transforms.RandomCrop.get_params(input, output_size=(512, 512))\n",
        "\n",
        "    input = TF.crop(input, i, j, h, w)\n",
        "    label = TF.crop(label, i, j, h, w)\n",
        "    \n",
        "    return input, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset   = SegmentationDataset('building', 'train')\n",
        "test_dataset    = SegmentationDataset('building', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 저장된 모델 가중치 로드\n",
        "#model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir_path = \"./trained\"\n",
        "\n",
        "def train(model, dataset, num_epoch = 10):\n",
        "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True) \n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters()) \n",
        "\n",
        "    for epoch in range(num_epoch):\n",
        "        model.train()\n",
        "\n",
        "        costs = []\n",
        "        \n",
        "        for batch in dataloader:\n",
        "            input, label = batch\n",
        "\n",
        "            input = input.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            hypothesis = model(input)\n",
        "            \n",
        "            cost = loss_func(hypothesis, label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            cost.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            costs.append(cost.item())\n",
        "\n",
        "        print(\"{0}/{1} : {2}\".format(epoch + 1, num_epoch, np.mean(costs)))\n",
        "        \n",
        "        #torch.save(model.state_dict(), os.path.join(output_dir_path, \"{0}_epoch_{1:d}.pt\".format(type(model).__class__.__name__, epoch + 1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epoch = 100\n",
        "\n",
        "#model1 = UNet().to(device)\n",
        "model2 = DeepLabV3Plus(num_classes=2).to(device)\n",
        "#model3 = HRNetV2(num_classes=1).to(device)\n",
        "\n",
        "#train(model1, train_dataset, num_epoch)\n",
        "train(model2, train_dataset, num_epoch)\n",
        "#train(model3, train_dataset, num_epoch)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
