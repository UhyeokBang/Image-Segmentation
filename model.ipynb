{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model.UNet import UNet\n",
        "from model.DeepLabV3Plus import DeepLabV3Plus\n",
        "from model.HRNetV2 import HRNetV2\n",
        "\n",
        "import os, gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "import random\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, data_type, mode):    \n",
        "    self.mode = mode\n",
        "    self.input, self.label = [], []\n",
        "\n",
        "    # 작업할 폴더의 경로\n",
        "    path = './dataset/{0}s'.format(data_type) \n",
        "\n",
        "    self.input_path = '{0}/{1}/{2}'.format(path, self.mode, \"data\")\n",
        "    self.label_path = '{0}/{1}/{2}'.format(path, self.mode, \"label\")\n",
        "\n",
        "    # 폴더 안에 있는 데이터 파일들의 이름을 추출\n",
        "    data_names = [name.split('.')[0] for name in os.listdir(self.input_path)]\n",
        "\n",
        "    # 데이터 전처리\n",
        "    for data_name in data_names:\n",
        "        input = '{0}/{1}.png'.format(self.input_path, data_name)\n",
        "        label = '{0}/{1}.png'.format(self.label_path, data_name)\n",
        "\n",
        "        #\"\"\" 컴퓨터 메모리(RAM)가 부족한 경우, 아래를 주석 해제하고 이 부분을 주석 처리\n",
        "        input = cv2.cvtColor(cv2.imread(input), cv2.COLOR_BGR2RGB)\n",
        "        label = cv2.imread(label, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        input = torch.FloatTensor(input).permute(2, 0, 1)\n",
        "        label = torch.LongTensor(label)\n",
        "        #\"\"\"\n",
        "\n",
        "        self.input.append(input)\n",
        "        self.label.append(label)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input = self.input[index]\n",
        "    label = self.label[index]\n",
        "    \n",
        "    \"\"\" 컴퓨터 메모리(RAM)가 부족한 경우, 위를 주석 처리하고 이 부분을 주석 해제\n",
        "    input_img = cv2.cvtColor(cv2.imread(input), cv2.COLOR_BGR2RGB)\n",
        "    label_img = cv2.imread(label, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    input = torch.FloatTensor(input_img).permute(2, 0, 1)\n",
        "    label = torch.LongTensor(label_img)\n",
        "    \"\"\"\n",
        "\n",
        "    label = label.unsqueeze(dim=0) \n",
        "    \n",
        "    params = transforms.RandomResizedCrop.get_params(input, scale=(0.5, 0.5), ratio=(3.0 / 4.0, 4.0 / 3.0))\n",
        "\n",
        "    input = TF.resized_crop(input, *params, size=(512, 512), interpolation=InterpolationMode.BILINEAR)\n",
        "    label = TF.resized_crop(label, *params, size=(512, 512), interpolation=InterpolationMode.NEAREST)\n",
        "\n",
        "    label = label.squeeze(dim=0)\n",
        "\n",
        "    # 좌우 뒤집기\n",
        "    if random.random() > 0.5:\n",
        "        input = TF.hflip(input)\n",
        "        label = TF.hflip(label)\n",
        "\n",
        "    # 상하 뒤집기\n",
        "    if random.random() > 0.5:\n",
        "        input = TF.vflip(input)\n",
        "        label = TF.vflip(label)\n",
        "\n",
        "    # 무작위 회전 각도 얻기\n",
        "    #angle = random.uniform(-60, 60)\n",
        "\n",
        "    # 이미지 및 라벨 무작위 회전\n",
        "    #input = TF.affine(input, angle=angle, translate=(0, 0), scale=1.0, shear=(0, 0), interpolation=InterpolationMode.BILINEAR)\n",
        "    #label = TF.affine(label, angle=angle, translate=(0, 0), scale=1.0, shear=(0, 0), interpolation=InterpolationMode.NEAREST)\n",
        "\n",
        "    return input, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset   = SegmentationDataset('building', 'train')\n",
        "test_dataset    = SegmentationDataset('building', 'test')\n",
        "\n",
        "#train_dataset   = SegmentationDataset('building', 'train')\n",
        "#test_dataset    = SegmentationDataset('building', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  predvs, labels = [], []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(dataloader, desc=\"Test Processed\"):\n",
        "        input, label = batch\n",
        "\n",
        "        input = input.to(device)\n",
        "\n",
        "        hypothesis = model(input)\n",
        "\n",
        "        predv = torch.argmax(hypothesis, dim=1).cpu()\n",
        "\n",
        "        predvs.extend(predv.numpy().ravel())\n",
        "        labels.extend(label.numpy().ravel())\n",
        "\n",
        "    # 평가 지표 mIoU를 추가할 것\n",
        "    print(\"Accuracy - {0:f}\\n\".format(accuracy_score(labels, predvs)))\n",
        "    print(\"F1 Score - {0:f}\\n\".format(f1_score(labels, predvs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_model_path = \"./trained\"\n",
        "\n",
        "def train(model : nn.Module, dataset, num_epoch = 10, lr=0.001):\n",
        "    if not hasattr(model, \"current_epoch\"): model.current_epoch = 0\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True) \n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(model.current_epoch, model.current_epoch + num_epoch):\n",
        "        print(\"# | Epoch - {0:03d} / {1:03d} | #\".format(epoch + 1, model.current_epoch + num_epoch))\n",
        "        print(\"=========================\")\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        costs = []\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=\"Batch Processed\"):\n",
        "            input, label = batch\n",
        "\n",
        "            input = input.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            hypothesis = model(input)\n",
        "            \n",
        "            cost = loss_func(hypothesis, label)\n",
        "\n",
        "            cost.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            costs.append(cost.item())\n",
        "\n",
        "        print(\"Current Average Loss - {0:f}\".format(np.mean(costs)))\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            path = \"{0}/{1}/epoch_{2:05d}.pt\".format(trained_model_path, model.__class__.__name__, epoch + 1)\n",
        "            \n",
        "            torch.save(model.state_dict(), path)\n",
        "\n",
        "            print(\"모델 파일({0}) 저장됨\\n\".format(path))\n",
        "        \n",
        "        #evaluate(model, dataloader)\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_trained_model(model : nn.Module, epoch):\n",
        "    model.load_state_dict(torch.load('{0}/{1}/epoch_{2:05d}.pt'.format(trained_model_path, model.__class__.__name__, epoch)))\n",
        "\n",
        "    model.current_epoch = epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# | Epoch - 201 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:50<00:00,  2.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.137729\n",
            "# | Epoch - 202 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.137967\n",
            "# | Epoch - 203 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.137706\n",
            "# | Epoch - 204 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.137325\n",
            "# | Epoch - 205 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.138039\n",
            "# | Epoch - 206 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.136736\n",
            "# | Epoch - 207 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.135517\n",
            "# | Epoch - 208 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.134607\n",
            "# | Epoch - 209 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.136180\n",
            "# | Epoch - 210 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.135803\n",
            "모델 파일(./trained/DeepLabV3Plus/epoch_00210.pt) 저장됨\n",
            "\n",
            "# | Epoch - 211 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.135213\n",
            "# | Epoch - 212 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.134260\n",
            "# | Epoch - 213 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed: 100%|██████████| 149/149 [00:48<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Average Loss - 0.135423\n",
            "# | Epoch - 214 / 300 | #\n",
            "=========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch Processed:  10%|█         | 15/149 [00:05<00:47,  2.85it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[40], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model2 \u001b[38;5;241m=\u001b[39m DeepLabV3Plus(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m load_trained_model(model2, \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[25], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataset, num_epoch, lr)\u001b[0m\n\u001b[0;32m     31\u001b[0m     cost\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 34\u001b[0m     costs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Average Loss - \u001b[39m\u001b[38;5;132;01m{0:f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mmean(costs)))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epoch = 100\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "#model1 = UNet().to(device)\n",
        "#train(model1, train_dataset, num_epoch)\n",
        "\n",
        "model2 = DeepLabV3Plus(num_classes=2).to(device)\n",
        "load_trained_model(model2, 200)\n",
        "\n",
        "train(model2, train_dataset, num_epoch, 1e-5)\n",
        "\n",
        "#model3 = HRNetV2(num_classes=2).to(device)\n",
        "#train(model3, train_dataset, num_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.667898593010439\n",
            "0.8054667656040412\n",
            "0.6372945454545454\n",
            "0.7183568288616038\n",
            "0.5880984525911309\n",
            "0.7734284985980118\n",
            "0.8133585978209379\n",
            "0.5793532866341188\n",
            "0.9106748804707613\n",
            "0.8642768367104694\n",
            "0.29069852403916413\n",
            "0.641165383654654\n",
            "0.6094653179190751\n",
            "0.8074713286087948\n",
            "0.8052073972473159\n",
            "0.548952155001977\n",
            "0.844330977279315\n",
            "0.0\n",
            "0.0\n",
            "0.5884727984127205\n",
            "0.7970941636849317\n",
            "0.7413197499421162\n",
            "0.6802978353959122\n",
            "0.0\n",
            "0.5204277356861993\n",
            "0.0\n",
            "0.5841247877224983\n",
            "0.6922002792738879\n",
            "0.16666666666666666\n",
            "0.13840453356582388\n",
            "0.7446076313894888\n",
            "0.46337579617834396\n",
            "0.7891471341343314\n",
            "0.7906254483462879\n",
            "0.6833238816425926\n",
            "0.8138687131697958\n",
            "0.7992187132301031\n",
            "0.9305430735652844\n",
            "0.750084071292456\n",
            "0.7298760472294351\n",
            "0.7371208867619691\n",
            "0.5610631917965424\n",
            "0.6105155691679428\n",
            "0.8274364783226723\n",
            "nan\n",
            "0.6861735009272615\n",
            "0.40425065731814197\n",
            "0.6800727019606326\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m label \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(label, cv2\u001b[38;5;241m.\u001b[39mCOLOR_GRAY2BGR)\n\u001b[0;32m     24\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mhconcat((\u001b[38;5;28minput\u001b[39m, label, pred)))\n\u001b[1;32m---> 26\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 테스트 할 모델을 선택해주세요!\n",
        "model = model2.cpu()\n",
        "\n",
        "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True) \n",
        "\n",
        "for batch in dataloader:\n",
        "    input, label = batch\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = torch.argmax(model(input[0].unsqueeze(dim=0)), dim=1).permute(1, 2, 0).numpy().astype(np.uint8) * 255\n",
        "        label = label[0].numpy().astype(np.uint8) * 255\n",
        "        input = input[0].permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "\n",
        "        i_or = np.count_nonzero(cv2.bitwise_or(label, pred))\n",
        "        i_and = np.count_nonzero(cv2.bitwise_and(label, pred))\n",
        "\n",
        "        print((i_and / i_or) if i_or != 0 else np.nan)\n",
        "\n",
        "        pred = cv2.cvtColor(pred, cv2.COLOR_GRAY2BGR)\n",
        "        label = cv2.cvtColor(label, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        cv2.imshow(\"result\", cv2.hconcat((input, label, pred)))\n",
        "\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
